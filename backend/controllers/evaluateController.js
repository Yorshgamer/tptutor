// controllers/evaluateController.js
import { ollamaRequest } from "../utils/ollamaClient.js";

/**
 * Intenta extraer un objeto JSON de forma tolerante desde un string.
 * - Busca el primer "{"
 * - Busca el √∫ltimo "}"
 * - Si no hay "}", asume que falta y la agrega
 */
export function extractJsonObjectLenient(str) {
  const trimmed = String(str || "").trim();
  if (!trimmed) return null;

  const start = trimmed.indexOf("{");
  if (start === -1) {
    // No hay ni una llave ‚Üí imposible
    return null;
  }

  let end = trimmed.lastIndexOf("}");

  let candidate;
  if (end === -1) {
    // No hay "}" ‚Üí asumimos que falt√≥ la llave de cierre
    candidate = trimmed.slice(start) + "}";
  } else {
    candidate = trimmed.slice(start, end + 1);
  }

  try {
    const obj = JSON.parse(candidate);
    return obj;
  } catch (e) {
    console.error("‚ùó No se pudo parsear ni siquiera el candidate:", e.message);
    console.error("Candidate problem√°tico:", candidate);
    return null;
  }
}

export async function evaluateOpen(req, res) {
  const { text, studentAnswer } = req.body || {};

  if (!text || !text.trim()) {
    return res
      .status(400)
      .json({ error: "Debe enviarse el texto base para evaluar." });
  }

  if (!studentAnswer || !studentAnswer.trim()) {
    return res.status(400).json({
      error: "Debe escribirse una respuesta del estudiante para evaluar.",
    });
  }

  try {
    const prompt = `
Eval√∫a la siguiente respuesta de un estudiante seg√∫n el texto dado.

TEXTO BASE:
${text}

RESPUESTA DEL ESTUDIANTE:
${studentAnswer}

Criterios:
1. Comprensi√≥n lectora: ¬øresponde al contenido del texto?
2. Coherencia: ¬ølas ideas tienen sentido o est√°n fuera de contexto?
3. Ortograf√≠a y redacci√≥n: ¬øhay errores graves o leves?
4. Profundidad: ¬øsolo repite o muestra an√°lisis?

Gu√≠a para puntuar (s√© exigente):
- 0-5: No entiende el texto o responde algo sin sentido. Ej: "Me gusta el sol porque es bonito."
- 6-10: Menciona algo del texto, pero con errores o frases sin sentido.
- 11-15: Entiende parcialmente el texto, pero con errores de redacci√≥n u ortograf√≠a.
- 16-20: Entiende claramente, redacta bien y reflexiona sobre el texto.

üëâ Ejemplos:
Texto: "El sol brilla y los ni√±os juegan en el parque."
Mala respuesta: "El sol est√° triste." ‚Üí Puntaje: 4 (no tiene relaci√≥n)
Regular: "Habla del sol y los ni√±os." ‚Üí Puntaje: 10
Buena: "El texto muestra alegr√≠a en un d√≠a soleado." ‚Üí Puntaje: 17

Responde *solo en JSON v√°lido* con esta estructura exacta:
{
  "score": n√∫mero del 0 al 20,
  "feedback": "Retroalimentaci√≥n breve (m√°x. 3 oraciones), indicando comprensi√≥n, errores ortogr√°ficos o de coherencia."
}
`.trim();

    const output = await ollamaRequest(prompt);
    const raw = String(output || "").trim();

    // 1) Intento directo
    try {
      const parsed = JSON.parse(raw);
      return res.json(parsed);
    } catch {
      console.warn("‚ö†Ô∏è JSON.parse directo fall√≥ en evaluateOpen, intentando lenient‚Ä¶");
    }

    // 2) Intento lenient (arreglar llave faltante o texto extra)
    const obj = extractJsonObjectLenient(raw);
    if (obj && typeof obj.score === "number" && typeof obj.feedback === "string") {
      return res.json(obj);
    }

    // 3) Nada funcion√≥ ‚Üí devolvemos raw para debug
    console.error("‚ö†Ô∏è No fue JSON v√°lido:", raw);
    return res.status(502).json({
      error: "La respuesta del modelo no fue v√°lida.",
      raw,
    });
  } catch (err) {
    console.error("‚ùå Error con Ollama:", err.message || err);
    res
      .status(500)
      .json({ error: "Error interno al evaluar resumen." });
  }
}
