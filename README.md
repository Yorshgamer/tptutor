# TPTUTOR üéì

![MERN Stack](https://img.shields.io/badge/MERN-Fullstack-blue)
![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED)
![Status](https://img.shields.io/badge/Status-Enabled-2496ED)

**TPTUTOR** es una aplicaci√≥n web full-stack que funciona como un **tutor virtual de lectura cr√≠tica**.

El sistema ayuda a estudiantes y docentes a desarrollar habilidades de pensamiento cr√≠tico mediante:
- ü§ñ **Generaci√≥n autom√°tica de preguntas** sobre textos utilizando IA.
- ‚öñÔ∏è **Detecci√≥n de sesgos y falacias** en los argumentos.
- ‚ö° **Automatizaci√≥n de flujos** (recordatorios y notificaciones) con n8n.

---

## üìã Tabla de Contenidos
1. [Descripci√≥n General](#descripci√≥n-general)
2. [Objetivos](#objetivos)
3. [Arquitectura](#arquitectura-del-sistema)
4. [Tecnolog√≠as](#tecnolog√≠as-principales)
5. [Pre-requisitos](#-pre-requisitos)
6. [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
7. [Ejecuci√≥n con Docker](#-ejecuci√≥n-con-docker-recomendado)
8. [Ejecuci√≥n Local (Manual)](#-ejecuci√≥n-local-manual)
9. [Testing](#-testing)

---

## üìñ Descripci√≥n General

El proyecto **TPTUTOR** tiene como finalidad apoyar el proceso educativo promoviendo la comprensi√≥n, el razonamiento y la argumentaci√≥n l√≥gica.

Este sistema est√° orientado a:
* **Estudiantes:** Reciben retroalimentaci√≥n inmediata y pr√°ctica personalizada.
* **Docentes:** Asignan textos, revisan estad√≠sticas y generan reportes.

---

## üéØ Objetivos

1.  Desarrollar un sistema **innovador y escalable** para la lectura cr√≠tica.
2.  Integrar **Inteligencia Artificial (Gemma:2b)** para el an√°lisis de textos.
3.  Implementar **automatizaci√≥n** de tareas con n8n.
4.  Aplicar metodolog√≠as √°giles y buenas pr√°cticas de ingenier√≠a de software.

---

## üèó Arquitectura del Sistema

La arquitectura sigue el modelo **MERN** contenerizado:
```mermaid
graph TD
    User((Usuario)) --> A[Frontend - React/Vite]
    A --> B[Backend - Express API]
    B --> C[(Base de Datos - MongoDB Atlas)]
    B --> D[Automatizaci√≥n - n8n Webhooks]
    B --> E["IA Local - Ollama (Gemma:2b)"]
```

## üõ† Tecnolog√≠as Principales

| √Årea | Tecnolog√≠as |
| :--- | :--- |
| **Frontend** | React.js, Redux Toolkit, Vite, TailwindCSS (opcional) |
| **Backend** | Node.js, Express.js, JWT, Multer |
| **Base de Datos** | MongoDB Atlas (Mongoose) |
| **IA** | Ollama (Modelo: gemma:2b), Hugging Face Transformers |
| **DevOps** | Docker, Docker Compose |
| **Testing** | Jest, Supertest |

## ‚öôÔ∏è Pre-requisitos

Antes de comenzar, aseg√∫rate de tener instalado:

### 1. Docker Desktop
Debe incluir **Docker Compose**. Es esencial para la contenerizaci√≥n.

### 2. Node.js (v18+)
*Solo necesario si vas a correr el proyecto manualmente sin Docker.*

### 3. Ollama
Es el motor de Inteligencia Artificial local.
* Descarga Ollama desde [ollama.com](https://ollama.com).
* Ejecuta este comando en tu terminal:
    ```bash
    ollama pull gemma:2b
    ```
    > **Nota:** La IA corre en tu m√°quina local (Host) y Docker se conecta a ella.

### 4. Cuenta en MongoDB Atlas
Necesitar√°s crear un cl√∫ster gratuito para obtener tu **URI de conexi√≥n**.

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Clonar el repositorio

```bash
git clone [https://github.com/tu-usuario/tptutor.git](https://github.com/tu-usuario/tptutor.git)
cd tptutor
```

### 2. Configurar Variables de Entorno (Backend)
Navega a la carpeta backend y crea un archivo .env copiando el siguiente contenido.

Importante: Aseg√∫rate de reemplazar <usuario> y <password> con tus credenciales reales de Mongo Atlas.
    ```bash
    
    # Archivo: backend/.env
    PORT=5000
    
    # Conexi√≥n a Base de Datos (MongoDB Atlas)
    MONGO_URI=mongodb+srv://<usuario>:<password>@cluster.mongodb.net/tptutor_db
    
    # Seguridad
    JWT_SECRET=tu_palabra_secreta_super_segura
    
    # Configuraci√≥n de IA (Apunta al Host desde Docker)
    OLLAMA_BASE_URL=[http://host.docker.internal:11434](http://host.docker.internal:11434)
    
    # Configuraci√≥n de Automatizaci√≥n (Webhook de n8n)
    N8N_WEBHOOK_READING_COMPLETED=[http://host.docker.internal:5678/webhook/tptutor/reading-completed](http://host.docker.internal:5678/webhook/tptutor/reading-completed)
    ```

### 3. Configurar Variables de Entorno (Frontend)
Navega a la carpeta frontend y crea un archivo .env:

```bash
# Archivo: frontend/.env
VITE_API_TARGET=http://localhost:5000
```

## Ejecuci√≥n con Docker (Recomendado)
Esta opci√≥n levanta toda la aplicaci√≥n (Frontend + Backend) autom√°ticamente y es la m√°s estable.

### 1. Iniciar Ollama en tu PC
Aseg√∫rate de que Ollama est√© corriendo en segundo plano en tu sistema operativo (no en Docker).

### 2. Levantar contenedores
Ejecuta en la ra√≠z del proyecto:

```bash

docker-compose up --build
3. Acceder a la aplicaci√≥n
Frontend: http://localhost:5173

Backend API: http://localhost:5000
```

## Ejecuci√≥n Local (Manual)
Si prefieres no usar Docker, puedes ejecutar cada parte por separado en terminales distintas.

### 1. Backend

```bash
cd backend
npm install
npm run dev
```
### 2. Frontend

```bash
cd frontend
npm install
npm run dev
```
## üß™ Testing
El proyecto utiliza Jest para realizar pruebas unitarias y de integraci√≥n en el servidor.

Ejecutar tests

```bash
cd backend
npm test
Esto generar√° un reporte de cobertura en la consola indicando qu√© m√≥dulos pasaron las pruebas.
```
